
import re
import numpy as np
import librosa
import hgtk
from difflib import SequenceMatcher
from g2pk import G2p
from dtw import dtw
from scipy.spatial.distance import euclidean
from scipy.spatial.distance import cosine
import base64
import httpx

API_KEY = "067ea6f9-1715-43ab-814f-e23876886b9b"

class PronunciationModel:
    def __init__(self):
        self.g2p = G2p()

    @staticmethod
    def extract_mfcc(audio_path, sr=16000):
        y, _ = librosa.load(audio_path, sr=sr)
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
        mfcc_mean = np.mean(mfcc, axis=1)
        mfcc_std = np.std(mfcc, axis=1)
        return np.concatenate((mfcc_mean, mfcc_std))

    @staticmethod
    def compare_mfcc(reference_mfcc, user_mfcc):
        return 1 - cosine(reference_mfcc, user_mfcc)

    
    def get_g2p(self, text):
        return self.g2p(text)

    @staticmethod
    def remove_spaces_and_punctuation(text):
        return re.sub(r'[^\w\s]', '', text).replace(" ", "")

    @staticmethod
    def compare_pronunciation(reference_pronunciation, user_pronunciation):
        ref_jamo = PronunciationModel.split_to_jamo(reference_pronunciation)
        user_jamo = PronunciationModel.split_to_jamo(user_pronunciation)
        feedback = []

        for i, (ref, user) in enumerate(zip(ref_jamo, user_jamo)):
            if ref != user:
                try:
                    # refì™€ userê°€ ìëª¨ ì„¸ ê°œë¡œ ë¶„í•´ë  ìˆ˜ ìˆì„ ë•Œë§Œ
                    ref_c, ref_v, ref_f = ref if len(ref) == 3 else (ref, '', '')
                    user_c, user_v, user_f = user if len(user) == 3 else (user, '', '')
                    feedback.append(f"{i+1}ë²ˆì§¸ ì´ˆì„± ì°¨ì´: '{ref_c}' vs '{user_c}'")
                    feedback.append(f"{i+1}ë²ˆì§¸ ì¤‘ì„± ì°¨ì´: '{ref_v}' vs '{user_v}'")
                    feedback.append(f"{i+1}ë²ˆì§¸ ì¢…ì„± ì°¨ì´: '{ref_f}' vs '{user_f}'")
                except Exception:
                    # fallback for unexpected input
                    feedback.append(f"{i+1}ë²ˆì§¸ ë°œìŒ ì°¨ì´: '{ref}' vs '{user}'")
        return feedback

    @staticmethod
    def split_text_to_characters(text):
        return list(text)

    @staticmethod
    def compare_text_by_characters(reference_text, user_text):
        reference_chars = PronunciationModel.split_text_to_characters(reference_text)
        user_chars = PronunciationModel.split_text_to_characters(user_text)
        match_count = sum(1 for r, u in zip(reference_chars, user_chars) if r == u)
        total_chars = max(len(reference_chars), len(user_chars))
        return match_count / total_chars * 100

    @staticmethod
    def compare_text_by_syllables(reference_text, user_text):
        matcher = SequenceMatcher(None, reference_text, user_text)
        return matcher.ratio() * 100

    @staticmethod
    def split_to_jamo(text):
        jamo_list = []
        for char in text:
            if hgtk.checker.is_hangul(char):
                jamo_list.extend(hgtk.letter.decompose(char))
            else:
                jamo_list.append(char)
        return jamo_list

    @staticmethod
    def jamo_distance(j1, j2):
        similar_vowels = [("ã…“", "ã…”"), ("ã…", "ã…”"), ("ã…—", "ã…œ"), ("ã…‘", "ã…•"), ("ã…›", "ã… ")]
        similar_consonants = [("ã„±", "ã…‹"), ("ã„·", "ã…Œ"), ("ã…‚", "ã…"), ("ã……", "ã…†"), ("ã…ˆ", "ã…Š")]
        if j1 == j2:
            return 0
        if (j1, j2) in similar_vowels or (j2, j1) in similar_vowels:
            return 0.5
        if (j1, j2) in similar_consonants or (j2, j1) in similar_consonants:
            return 0.5
        return 1

    @staticmethod
    def compare_jamo_dtw(reference_text, user_text):
        ref_jamo = PronunciationModel.split_to_jamo(reference_text)
        user_jamo = PronunciationModel.split_to_jamo(user_text)
        ref_jamo_np = np.array(ref_jamo).reshape(-1, 1)
        user_jamo_np = np.array(user_jamo).reshape(-1, 1)
        dist, _, _, _ = dtw(ref_jamo_np, user_jamo_np, dist=lambda x, y: PronunciationModel.jamo_distance(x[0], y[0]))
        return dist

    @staticmethod
    def compare_syllables(reference_text, user_text):
        ref_syllables = list(reference_text)
        user_syllables = list(user_text)
        if len(ref_syllables) == len(user_syllables):
            return 0
        lcs_length = PronunciationModel.lcs(ref_syllables, user_syllables)
        return len(ref_syllables) - lcs_length

    @staticmethod
    def lcs(X, Y):
        m, n = len(X), len(Y)
        dp = [[0] * (n + 1) for _ in range(m + 1)]
        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if X[i - 1] == Y[j - 1]:
                    dp[i][j] = dp[i - 1][j - 1] + 1
                else:
                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])
        return dp[m][n]

    
    @staticmethod
    def calculate_score(reference_text, user_text, reference_audio, user_audio):
        syllable_accuracy = PronunciationModel.compare_text_by_syllables(reference_text, user_text)
        character_accuracy = PronunciationModel.compare_text_by_characters(reference_text, user_text)
        jamo_dtw = PronunciationModel.compare_jamo_dtw(reference_text, user_text)
        missing_syllables = PronunciationModel.compare_syllables(reference_text, user_text)
        lcs_score = PronunciationModel.lcs(reference_text, user_text)
        mfcc_similarity = PronunciationModel.compare_mfcc(reference_audio, user_audio)
        mfcc_dtw = PronunciationModel.compare_mfcc_with_dtw(reference_audio, user_audio)

        syllable_score = syllable_accuracy
        character_score = character_accuracy
        jamo_score = 100 - jamo_dtw
        missing_score = max(0, 100 - (missing_syllables * 10))
        lcs_score = (lcs_score / len(reference_text)) * 100
        mfcc_similarity_score = mfcc_similarity * 100
        mfcc_dtw_score = max(0, 100 - (mfcc_dtw / 10))
        mfcc_score = (mfcc_similarity_score * 0.5) + (mfcc_dtw_score * 0.5)

        total_score = (syllable_score * 0.1 +
                       character_score * 0.1 +
                       jamo_score * 0.25 +
                       missing_score * 0.05 +
                       lcs_score * 0.25 +
                       mfcc_score * 0.25)

        return {
            "total": total_score,
            "syllable_score": syllable_score,
            "character_score": character_score,
            "jamo_score": jamo_score,
            "missing_score": missing_score,
            "lcs_score": lcs_score,
            "mfcc_score": mfcc_score,
        }
    @staticmethod
    def compare_mfcc_with_dtw(reference_mfcc, user_mfcc):
        from dtw import dtw

        ref_seq = reference_mfcc.T
        user_seq = user_mfcc.T

        dist, _, _, _ = dtw(
            ref_seq, user_seq,
            dist=lambda x, y: euclidean(x.ravel(), y.ravel())  # ğŸ”¥ flatten to 1D
        )
        return dist
    @staticmethod
    def get_mfcc_dtw_feedback(ref_mfcc, user_mfcc):
        from dtw import dtw

        # ê¸¸ì´ ë§ì¶”ê¸° (í•„ìš”ì‹œ padding ë˜ëŠ” trimming ê³ ë ¤ ê°€ëŠ¥)
        ref_seq = ref_mfcc.T
        user_seq = user_mfcc.T
       
        dist, _, _, _ = dtw(
            ref_seq, user_seq,
            dist=lambda x, y: euclidean(x.ravel(), y.ravel())  # ğŸ”¥ flatten to 1D
        )

        # ë‹¨ìˆœ ê·œì¹™ ì˜ˆì‹œ: ì†ë„ë‚˜ ì™œê³¡ì´ ì‹¬í•œ êµ¬ê°„ ì²´í¬
        if dist > 1000:
            return ["ë°œìŒ ì†ë„ê°€ ê¸°ì¤€ë³´ë‹¤ ë¹ ë¥´ê±°ë‚˜ ëŠë¦½ë‹ˆë‹¤. ì¼ì •í•˜ê²Œ ë°œìŒí•´ë³´ì„¸ìš”."]
        elif dist > 500:
            return ["ì¼ë¶€ êµ¬ê°„ì´ ê¸¸ê±°ë‚˜ ì§§ìŠµë‹ˆë‹¤. ì¼ì •í•œ ì†ë„ë¡œ ë°œìŒí•´ë³´ì„¸ìš”."]
        else:
            return ["ë°œìŒ ì†ë„ì™€ ê¸¸ì´ëŠ” ë¹„êµì  ì•ˆì •ì ì…ë‹ˆë‹¤."]

    
    @staticmethod
    def analyze_dtw_alignment(reference_mfcc, user_mfcc):
        """DTW warping pathë¡œ ë°œìŒ ê¸¸ì´ ì°¨ì´ í”¼ë“œë°±"""
        from dtw import dtw
        from scipy.spatial.distance import euclidean

        ref_seq = reference_mfcc.T
        user_seq = user_mfcc.T

        dist, cost, acc_cost, path = dtw(
            ref_seq,
            user_seq,
            dist=lambda x, y: euclidean(x.ravel(), y.ravel())
        )

        ref_indices, user_indices = path
        feedback = []

        stretch_count = 0
        compress_count = 0

        for i in range(1, len(ref_indices)):
            ref_prev, user_prev = ref_indices[i - 1], user_indices[i - 1]
            ref_curr, user_curr = ref_indices[i], user_indices[i]

            ref_delta = ref_curr - ref_prev
            user_delta = user_curr - user_prev

            if user_delta > ref_delta:
                stretch_count += 1
            elif user_delta < ref_delta:
                compress_count += 1

        if stretch_count > 5:
            feedback.append("ë°œìŒì„ ê¸°ì¤€ë³´ë‹¤ ê¸¸ê²Œ ë„ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ì¡°ê¸ˆ ë” ê°„ê²°í•˜ê²Œ ë°œìŒí•´ë³´ì„¸ìš”.")
        if compress_count > 5:
            feedback.append("ë°œìŒì´ ê¸°ì¤€ë³´ë‹¤ ì§§ìŠµë‹ˆë‹¤. ì²œì²œíˆ ë˜ë°•ë˜ë°• ë°œìŒí•´ë³´ì„¸ìš”.")
        if not feedback:
            feedback.append("ë°œìŒ ì†ë„ì™€ ê¸¸ì´ëŠ” ë¹„êµì  ì•ˆì •ì ì…ë‹ˆë‹¤.")

        return feedback

    @staticmethod
    def analyze_mfcc_bands(ref_mfcc, user_mfcc):
        """MFCC í‰ê·  ì°¨ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŠ¹ì • ëŒ€ì—­ì˜ ë¶€ì •í™•ì„± í”¼ë“œë°±"""
        ref_mfcc = np.array(ref_mfcc)
        user_mfcc = np.array(user_mfcc)

        if ref_mfcc.shape != user_mfcc.shape or ref_mfcc.ndim != 1:
            return ["MFCC í”¼ë“œë°± ë¶„ì„ ì‹¤íŒ¨: ì˜ëª»ëœ ì…ë ¥ í˜•íƒœì…ë‹ˆë‹¤."]

        diff = np.abs(ref_mfcc - user_mfcc)

        feedback = []

        low_band = np.mean(diff[:4])     # ì €ì£¼íŒŒ
        mid_band = np.mean(diff[4:9])    # ì¤‘ì£¼íŒŒ
        high_band = np.mean(diff[9:])    # ê³ ì£¼íŒŒ

        threshold = 12.0  # âœ… ì´ì „ë³´ë‹¤ ë†’ì€ ì„ê³„ê°’
        minor_threshold = 7.0  # âœ… ê²½ê³  ìˆ˜ì¤€

        if low_band > threshold:
            feedback.append("ì €ì£¼íŒŒ ëŒ€ì—­ì˜ ë°œìŒì´ ì•½í•©ë‹ˆë‹¤. ëª©ì†Œë¦¬ë¥¼ ê¹Šì´ ë‚´ë³´ì„¸ìš”.")
        elif low_band > minor_threshold:
            feedback.append("ì €ì£¼íŒŒ ëŒ€ì—­ì´ ì¡°ê¸ˆ ì•½í•©ë‹ˆë‹¤. ì•ˆì •ê° ìˆê²Œ ë°œìŒí•´ë³´ì„¸ìš”.")

        if mid_band > threshold:
            feedback.append("ì¤‘ê°„ ëŒ€ì—­ì˜ ë°œìŒì´ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤. ì²œì²œíˆ ë˜ë°•ë˜ë°• ë°œìŒí•´ë³´ì„¸ìš”.")
        elif mid_band > minor_threshold:
            feedback.append("ì¤‘ê°„ ëŒ€ì—­ì´ ë‹¤ì†Œ í”ë“¤ë¦½ë‹ˆë‹¤. ë¦¬ë“¬ì„ ìœ ì§€í•´ë³´ì„¸ìš”.")

        if high_band > threshold:
            feedback.append("ê³ ì£¼íŒŒ ëŒ€ì—­ì˜ ë°œìŒì´ ë‚ ì¹´ë¡­ì§€ ëª»í•©ë‹ˆë‹¤. ëìŒì„ ë˜ë ·í•˜ê²Œ í•´ë³´ì„¸ìš”.")
        elif high_band > minor_threshold:
            feedback.append("ê³ ì£¼íŒŒ ëŒ€ì—­ì´ ë‹¤ì†Œ íë¦¿í•©ë‹ˆë‹¤. ë°œìŒì„ ëª…í™•íˆ í•´ë³´ì„¸ìš”.")
        return feedback

    @staticmethod
    async def transcribe_with_etri(file_path, script=""):
        url = "http://aiopen.etri.re.kr:8000/WiseASR/PronunciationKor"
        headers = {
            "Content-Type": "application/json; charset=UTF-8",
            "Authorization": API_KEY
        }

        with open(file_path, "rb") as file:
            audio_contents = base64.b64encode(file.read()).decode("utf-8")

        data = {
            "argument": {
                "language_code": "korean",
                "audio": audio_contents,
            }
        }

        async with httpx.AsyncClient(timeout=30.0) as client:
            try:
                response = await client.post(url, headers=headers, json=data)
                if response.status_code == 200:
                    result = response.json()
                    if result.get('result') == 0:
                        return result['return_object']['recognized']
            except httpx.ReadTimeout:
                print("âŒ [ETRI] ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âŒ [ETRI] ì˜¤ë¥˜ ë°œìƒ: {e}")

            return None

        if response.status_code == 200:
            result = response.json()
            if result.get('result') == 0:
                return result['return_object']['recognized']
        return None
